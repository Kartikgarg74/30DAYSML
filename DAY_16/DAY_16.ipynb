{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b86322-25bd-49df-9e65-c16157366a5e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d4a7ad6-6234-4263-b864-762550e09c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd7c223-5c8f-43e1-af3c-71fe1a5f9753",
   "metadata": {},
   "source": [
    "## Data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b870d422-946b-4ea6-9739-12b1afcb3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset (10 classes of images)\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the data (scale between 0 and 1)\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d53ae4-53e5-4a41-aff8-242e6b8164e5",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0659b44-a38e-4fab-b207-335e9eacb5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    # Convolutional layer with 32 filters, 3x3 kernel, and ReLU activation\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    # MaxPooling layer with 2x2 pool size\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Second convolutional layer with 64 filters\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Third convolutional layer with 128 filters\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    # Flatten the feature maps to a 1D vector for input to the fully connected layer\n",
    "    Flatten(),\n",
    "    \n",
    "    # Fully connected layer with 128 neurons\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Dropout layer to prevent overfitting\n",
    "    \n",
    "    # Output layer with 10 neurons for 10 classes, softmax activation\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee332b7a-3e92-4fcb-8e05-d3813f28ca80",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb2d59ae-8a25-4a6c-85bc-bd235d486fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685c6a47-0c82-471a-b195-a0b6d46d88b7",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a400f53d-5e87-4265-a729-9172d4121ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.2851 - loss: 1.9115 - val_accuracy: 0.5229 - val_loss: 1.3260\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.5138 - loss: 1.3496 - val_accuracy: 0.5942 - val_loss: 1.1399\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.5900 - loss: 1.1632 - val_accuracy: 0.6483 - val_loss: 1.0062\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.6291 - loss: 1.0525 - val_accuracy: 0.6330 - val_loss: 1.0342\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.6637 - loss: 0.9661 - val_accuracy: 0.6883 - val_loss: 0.8934\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.6892 - loss: 0.8932 - val_accuracy: 0.6945 - val_loss: 0.8757\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.7122 - loss: 0.8274 - val_accuracy: 0.6927 - val_loss: 0.8716\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 16ms/step - accuracy: 0.7327 - loss: 0.7688 - val_accuracy: 0.7155 - val_loss: 0.8200\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.7454 - loss: 0.7396 - val_accuracy: 0.7227 - val_loss: 0.8250\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.7583 - loss: 0.6967 - val_accuracy: 0.7243 - val_loss: 0.8223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x154161c70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3274c2c6-caa3-4a47-9c97-93fac57761a7",
   "metadata": {},
   "source": [
    "## evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80bfaa67-ce64-4c0a-b326-55e6fd9fde2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7282 - loss: 0.8129\n",
      "Test accuracy: 0.7243000268936157\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc2407b-85a3-4855-8f15-03fb79a0c02a",
   "metadata": {},
   "source": [
    "## CNN feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83b0586e-3d36-4833-9284-0c28f425cd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the filters from the first convolutional layer\n",
    "filters = model.layers[0].get_weights()[0]\n",
    "\n",
    "# Plot the filters\n",
    "for i in range(filters.shape[3]):\n",
    "    plt.subplot(8, 8, i+1)\n",
    "    plt.imshow(filters[:, :, 0, i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b6316d-60fb-4a64-93d0-5396bbb270a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
